---
title: "Generalized Boosted Regression Model (GBM)"
author: "Feature space partition ensemble model for replication (FESPAE)"
date: "EGG data-based experiments"
output:
  pdf_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

**Article:** Lizbeth Naranjo, Carlos J. Perez, Daniel F. Merino (2025). 
A data ensemble-based approach for detecting vocal disorders using replicated acoustic biomarkers from electroglottography.  
*Sensing and Bio-Sensing Research Journal*, vol, num, pages. 

```{r, eval=TRUE, include=TRUE, message=FALSE, warning=FALSE, echo=TRUE, cache=FALSE, results=TRUE,  comment=""}   
library(tidyverse) 
library(gbm)
## change the address where the file will be saved 
address = "~/Documents/GitHub/" 
setwd("~/Documents/GitHub/") 
```

# EGG data-based experiments 

```{r, eval=TRUE, include=TRUE, message=FALSE, warning=FALSE, echo=TRUE, cache=FALSE, results=TRUE,  comment="", out.width="100%"}  
## Comment or uncomment the options: EGG-a, EGG-i, EGG-u
```

```{r, eval=TRUE, include=TRUE, message=FALSE, warning=FALSE, echo=TRUE, cache=FALSE, results=TRUE,  comment="", out.width="100%"}  
## EGG-a
## datos2 <- read.csv(paste0(address,"a_egg_saarbrucken.csv"),
##                   sep = ";",header=TRUE, dec=",")

## name of the files to save results
## archivo = "FESPAE_crossval_strata_allvar_GBM_Saarbruken_egg_a" 
```

```{r, eval=TRUE, include=TRUE, message=FALSE, warning=FALSE, echo=TRUE, cache=FALSE, results=TRUE,  comment="", out.width="100%"}  
## EGG-i
datos2 <- read.csv(paste0(address,"i_egg_saarbrucken.csv"),
                   sep = ";",header=TRUE, dec=",")

## name of the files to save results
archivo = "FESPAE_crossval_strata_allvar_GBM_Saarbruken_egg_i" 
```

```{r, eval=TRUE, include=TRUE, message=FALSE, warning=FALSE, echo=TRUE, cache=FALSE, results=TRUE,  comment="", out.width="100%"}  
## EGG-u
## datos2 <- read.csv(paste0(address,"u_egg_saarbrucken.csv"),
##                   sep = ";",header=TRUE, dec=",")

## name of the files to save results
## archivo = "FESPAE_crossval_strata_allvar_GBM_Saarbruken_egg_u" 
```

```{r, eval=TRUE, include=TRUE, message=FALSE, warning=FALSE, echo=TRUE, cache=FALSE, results=TRUE,  comment="", out.width="100%"}  
dim(datos2)
summary(datos2)
head(datos2)
```

\newpage
## Re-Scale explanatory variables 

```{r, eval=TRUE, include=TRUE, message=FALSE, warning=FALSE, echo=TRUE, cache=FALSE, results=TRUE,  comment="", out.width="100%"} 
## Scale the variables
datos2 <- as.data.frame(datos2)
datos2$STATUS_fact = as.factor(as.numeric(factor(datos2$status_fact)))

table(datos2$STATUS_fact)

datos <- transform(datos2,  
sJITTER= scale(JITTER), sSHIMMER= scale(SHIMMER), sCPP= scale(CPP), 
sD2= scale(D2), sFZCF= scale(FZCF), sGNE= scale(GNE), 
sHNR= scale(HNR), sHURST= scale(HURST), sLZ= scale(LZ),
sMFCC0= scale(MFCC0),  
sMFCC1= scale(MFCC1), sMFCC2= scale(MFCC2), sMFCC3= scale(MFCC3), 
sMFCC4= scale(MFCC4), sMFCC5= scale(MFCC5), sMFCC6= scale(MFCC6), 
sMFCC7= scale(MFCC7), sMFCC8= scale(MFCC8), sMFCC9= scale(MFCC9), 
sMFCC10= scale(MFCC10), sMFCC11= scale(MFCC11), sMFCC12= scale(MFCC12),  
sPERMUTATION= scale(PERMUTATION), sPPE= scale(PPE), sSHANNON= scale(SHANNON),
sZCR= scale(ZCR), 
senergyentropy= scale(energyentropy), sspectralcentroid= scale(spectralcentroid), 
sspectralspread= scale(spectralspread), sspectralentropy= scale(spectralentropy), 
sspectralrolloff= scale(spectralrolloff), sRPDE= scale(RPDE)) 

datos$ID_fact = rep(1:225,each=3)

dim(datos)

## data set 
trainc <- datos %>% select(
sJITTER, sSHIMMER, sCPP, sD2, sFZCF, 
sGNE, sHNR, sHURST, sLZ, sMFCC0, 
sMFCC1, sMFCC2, sMFCC3, sMFCC4, sMFCC5, 
sMFCC6, sMFCC7, sMFCC8, sMFCC9, sMFCC10, 
sMFCC11, sMFCC12, 
sPERMUTATION, sPPE, sSHANNON, sZCR, 
senergyentropy, sspectralcentroid, sspectralspread, 
sspectralentropy, sspectralrolloff, sRPDE,
STATUS_fact,SEX, rep,ID_fact)  
```

\clearpage 
# Crossvalidation 

## Subspaces

```{r, echo=TRUE, eval=TRUE, fig.show="hold", include=TRUE, out.width="100%", warning=FALSE, message=FALSE} 
## Partition of subspaces
## The feature space is randomly partitioned into K subspaces with roughly equal sizes
## k = number of predictors
## K = subspaces 

K0 = 4  ## sub-spaces
k = 32  ## explanatory variables  
k2 = round(k/K0)
space = 1:k
subspaces = rep(list(rep(NA,k2)),K0)  ## Subspaces 
set.seed(12345)
for(j in 1:(K0-1)){
    space1 = sample(space, size=k2, replace=FALSE)
    space = setdiff(space,space1)
    subspaces[[j]] = space1[order(space1)]
}
space1 = space
subspaces[[K0]] = space1[order(space1)]
## 32 features = 1x32, 2x16, 4x8,  
subspaces
```

\clearpage 
## Training and testing data subsets  

```{r, echo=TRUE, eval=TRUE, fig.show="hold", include=TRUE, out.width="100%", warning=FALSE, message=FALSE} 
## Select data: 75% training & 25% testing stratified per category
SIM = 100   ## repeat N times the cross-validation process
N = 225   ## sample size 
Nfit = 168   ## sample size for training subset
Ntest = 57   ## sample size for testing subset
Ncat = 75   ## sample size per category
Ncatfit = 56   ## training per category 
Ncattest = 19   ## testing per category
FIT <- matrix(0,SIM,Nfit)   ## training subsets 
TEST <- matrix(0,SIM,Ntest)   ## testing subsets 

categoria = trainc %>% filter(rep==1) %>% select(STATUS_fact)
categoria = as.numeric(categoria$STATUS_fact)
id = 1:N
set.seed(12345)
for(si in 1:SIM){
  for(j in 1:3){ 
    idcat = id[categoria==j]   ## stratified per category j
    ran0 = sample(idcat, size=Ncatfit, replace=FALSE)
    
    FIT[si,(j-1)*Ncatfit+1:Ncatfit] <- sort(ran0)
    TEST[si,(j-1)*Ncattest+1:Ncattest] <- setdiff(idcat,ran0)
} }
```

\newpage 
## Classification metrics for models predicting nominal outcomes

```{r, echo=TRUE, eval=TRUE, fig.show="hold", include=TRUE, out.width="100%", warning=FALSE, message=FALSE} 
## Functions to compute classification metrics 
## Ytrue = true response variable
## Ypred = predicted outcome
## cat = category 
## TP = true positive 
## TN = true negative
## FP = false positive 
## FN = false negative 

## Function to compute the precision per class=cat
fn_precision_class <- function(Ytrue,Ypred,cat){ 
  TP = sum(Ypred[Ytrue==cat]==cat)
  FP = sum(Ypred[Ytrue!=cat]==cat)
  precision = TP/(TP+FP)
  return(precision)
}

## Function to compute the recall per class=cat
fn_recall_class <- function(Ytrue,Ypred,cat){ ## cat==category
  TP = sum(Ypred[Ytrue==cat]==cat)
  FN = sum(Ypred[Ytrue==cat]!=cat)
  recall = TP/(TP+FN)  
  return(recall)
}

## Function to compute the F1-score per class=cat
fn_f1score_class <- function(Ytrue,Ypred,cat){ ## cat==category
  TP = sum(Ypred[Ytrue==cat]==cat)
  FP = sum(Ypred[Ytrue!=cat]==cat)
  FN = sum(Ypred[Ytrue==cat]!=cat)
  precision = TP/(TP+FP)
  recall = TP/(TP+FN)  
  f1score = 2*(precision*recall)/(precision+recall)
  return(f1score)
}

## To save classification metrics 
## Fitxxx: metric for training subset. Testxxx: metric for testing subset
FitAccuracy = TestAccuracy <- array(NA,dim=c(SIM,1))  ## Accuracy Rate
FitPrecisionClass = TestPrecisionClass <- array(NA,dim=c(SIM,1,3))  ## Precision per class
FitRecallClass = TestRecallClass <- array(NA,dim=c(SIM,1,3))  ## Recall per class
FitF1ScoreClass = TestF1ScoreClass <- array(NA,dim=c(SIM,1,3))  ## F1-score per class
FitPrecisionMacroAve = TestPrecisionMacroAve <- array(NA,dim=c(SIM,1))  ## Precision Macro Average
FitRecallMacroAve = TestRecallMacroAve <- array(NA,dim=c(SIM,1))  ## Recall Macro Average
FitF1ScoreMacroAve = TestF1ScoreMacroAve <- array(NA,dim=c(SIM,1))  ## F1-score Macro Average 
```

\newpage
## Model estimation  

```{r, echo=TRUE, eval=TRUE, fig.show="hold", include=TRUE, out.width="100%", warning=FALSE, message=FALSE, error=TRUE} 
##--------------------------------------------------
for(sim in 1:SIM){ ### BEGIN sim
##--------------------------------------------------
    
my_fit = FIT[sim,]   ## training subset 
my_test = TEST[sim,]   ## testing subset 

## Training data subset 
train1 <- trainc %>% filter(ID_fact%in%my_fit, rep==1)  ## repetition=1
train2 <- trainc %>% filter(ID_fact%in%my_fit, rep==2)  ## repetition=2 
train3 <- trainc %>% filter(ID_fact%in%my_fit, rep==3)  ## repetition=3 

Yc = train1$STATUS_fact   ## categorical response variable for training
n = length(Yc)  
G = 3 # classes

## Testing data subset
test1 <- trainc %>% filter(ID_fact%in%my_test, rep==1)  ## repetition=1
test2 <- trainc %>% filter(ID_fact%in%my_test, rep==2)  ## repetition=2
test3 <- trainc %>% filter(ID_fact%in%my_test, rep==3)  ## repetition=3

Yc.new = test1$STATUS_fact   ## categorical response variable for testing 
n.new = length(Yc.new)

## Delete variables which are not used 
train1 <- train1 %>% select(-c(rep,ID_fact))
train2 <- train2 %>% select(-c(rep,ID_fact))
train3 <- train3 %>% select(-c(rep,ID_fact))
test1 <- test1 %>% select(-c(rep,ID_fact))
test2 <- test2 %>% select(-c(rep,ID_fact))
test3 <- test3 %>% select(-c(rep,ID_fact))

##--------------------------------------------------
## Algorithm FESPAE 
## Feature space partition ensemble model for replication 
##-------------------------------------------------- 

## Algo1: The feature space is randomly partitioned into M subspaces, {S1,S2,...,SM}

K0 = 4  ## sub-spaces
k = 32  ## explanatory variables  
k2 = round(k/K0)
space = 1:k
subspaces = rep(list(rep(NA,k2)),K0)  ## Subspaces 
set.seed(12345)
for(j in 1:(K0-1)){
    space1 = sample(space, size=k2, replace=FALSE)
    space = setdiff(space,space1)
    subspaces[[j]] = space1[order(space1)]
}
space1 = space
subspaces[[K0]] = space1[order(space1)]
# 32 features = 1x32, 2x16, 4x8,  

##--------------------------------------------------
## Algo2: for feature subspace m = 1 to M do

pred.vgam = array(NA,dim=c(n,G,K0,3))  ## 3 repetitions
pred.new.vgam = array(NA,dim=c(n.new,G,K0,3))  ## 3 repetitions
##--------------------------------------------------
## Algo3: for replication j = 1 to J do 

## REPLICATION j=1: 
for(parti1 in 1:K0){  ## partition of the subspaces
train1_par = train1[,c(subspaces[[parti1]],k+1)] 
test1_par = test1[,c(subspaces[[parti1]])]   

## Algo4: Fit a classifier $T(xj,z)$, $xj\in Sm$, to the training data 
mod1 <- gbm( 
  formula = STATUS_fact ~ . ,
  distribution = "multinomial" , 
  data = train1_par ,
  n.trees = 100  ,
  interaction.depth = 5,
  shrinkage = 0.3,
  bag.fraction = 0.5,
  train.fraction = 1.0,
  n.cores = NULL # will use all cores by default
  )
## summary(mod1)

## Algo5: Compute the C response probabilities {\pi^(m,j)_{ic}}, for i=1,...,n.  
## Predictions
predict1.vgam <- predict(mod1, newdata=train1_par, n.trees=100, "response")
predict1.new.vgam <- predict(mod1, newdata=test1_par, n.trees=100, "response")

pred.vgam[,,parti1,1] = predict1.vgam
pred.new.vgam[,,parti1,1] = predict1.new.vgam 
}

## REPLICATION j=2: 
for(parti2 in 1:K0){  ## partition of the subspaces
train2_par = train2[,c(subspaces[[parti2]],k+1)] 
test2_par = test2[,c(subspaces[[parti2]])]   

## Algo4: Fit a classifier $T(xj,z)$, $xj\in Sm$, to the training data 
mod2 <- gbm( 
  formula = STATUS_fact ~ . ,
  distribution = "multinomial" , 
  data = train2_par ,
  n.trees = 100  ,
  interaction.depth = 5,
  shrinkage = 0.3,
  bag.fraction = 0.5,
  train.fraction = 1.0,
  n.cores = NULL # will use all cores by default
  )
## summary(mod2)

## Algo5: Compute the C response probabilities {\pi^(m,j)_{ic}}, for i=1,...,n.  
## Predictions
predict2.vgam <- predict(mod2, newdata=train2_par, n.trees=100, "response")
predict2.new.vgam <- predict(mod2, newdata=test2_par, n.trees=100, "response")

pred.vgam[,,parti2,2] = predict2.vgam
pred.new.vgam[,,parti2,2] = predict2.new.vgam
}

## REPLICATION j=3: 
for(parti3 in 1:K0){  ## partition of the subspaces
train3_par = train3[,c(subspaces[[parti3]],k+1)] 
test3_par = test3[,c(subspaces[[parti3]])]   

## Algo4: Fit a classifier $T(xj,z)$, $xj\in Sm$, to the training data 
mod3 <- gbm( 
  formula = STATUS_fact ~ . ,
  distribution = "multinomial" , 
  data = train3_par ,
  n.trees = 100  ,
  interaction.depth = 5,
  shrinkage = 0.3,
  bag.fraction = 0.5,
  train.fraction = 1.0,
  n.cores = NULL # will use all cores by default
  )
## summary(mod3)

## Algo5: Compute the C response probabilities {\pi^(m,j)_{ic}}, for i=1,...,n.  
## Predictions
predict3.vgam <- predict(mod3, newdata=train3_par, n.trees=100, "response")
predict3.new.vgam <- predict(mod3, newdata=test3_par, n.trees=100, "response")

pred.vgam[,,parti3,3] = predict3.vgam
pred.new.vgam[,,parti3,3] = predict3.new.vgam 
} 
##--------------------------------------------------
## Algo6: End for replication j = 1 to J 
## Algo7: End for feature subspace m = 1 to M
##--------------------------------------------------
## Algo8: Output: compute the response probabilities $\pi_{ic} = mean({\pi^(m,j)_{ic}})

pred.ave.vgam = apply(pred.vgam,c(1,2),mean) 

### Predict new subjects 
pred.ave.new.vgam = apply(pred.new.vgam,c(1,2),mean) 

##--------------------------------------------------
## Algo8: Output: compute the response category T*(x,z) = arg max {\pi_{ic}}

pred.vgam_max <- apply(pred.ave.vgam, 1, which.max)

### Predict new subjects 
pred.new.vgam_max <- apply(pred.ave.new.vgam, 1, which.max)

##--------------------------------------------------
## End FESPAE
##--------------------------------------------------
## Classification Metrics for models predicting nominal outcomes

## Accuracy Rate 
FitAccuracy[sim,] = c(sum(Yc==pred.vgam_max)/n) 

TestAccuracy[sim,] = c(sum(Yc.new==pred.new.vgam_max)/n.new) 

## Precision
for(cate in 1:3){
  FitPrecisionClass[sim,1, cate] = fn_precision_class(Yc, pred.vgam_max, cate)
  TestPrecisionClass[sim,1, cate] = fn_precision_class(Yc.new, pred.new.vgam_max, cate)
}
FitPrecisionMacroAve[sim, 1] = mean(FitPrecisionClass[sim, 1,])
TestPrecisionMacroAve[sim,1] = mean(TestPrecisionClass[sim,1,])
 
## Recall
for(cate in 1:3){
  FitRecallClass[sim,1, cate] = fn_recall_class(Yc, pred.vgam_max, cate)
  TestRecallClass[sim,1, cate] = fn_recall_class(Yc.new, pred.new.vgam_max, cate)
}
FitRecallMacroAve[sim, 1] = mean(FitRecallClass[sim, 1,])
TestRecallMacroAve[sim,1] = mean(TestRecallClass[sim,1,])

## F1-Score
for(cate in 1:3){
  FitF1ScoreClass[sim,1, cate]= fn_f1score_class(Yc, pred.vgam_max, cate)
  TestF1ScoreClass[sim,1, cate] = fn_f1score_class(Yc.new, pred.new.vgam_max, cate)
}
FitF1ScoreMacroAve[sim, 1] = mean(FitF1ScoreClass[sim, 1,]) 
TestF1ScoreMacroAve[sim,1] = mean(TestF1ScoreClass[sim,1,]) 

##--------------------------------------------------
} ## END sim 
##--------------------------------------------------
```

\newpage
# Results 

## Accuracy Rate 

```{r, echo=TRUE, eval=TRUE, fig.show="hold", include=TRUE, out.width="100%", warning=FALSE, message=FALSE} 
columna = c("ensemble")
renglon = c("fit_mean","fit_sd","test_mean","test_sd")

summary(FitAccuracy) 
apply(FitAccuracy,2,"sd",na.rm=TRUE)
summary(TestAccuracy)
apply(TestAccuracy,2,"sd",na.rm=TRUE)

RESaccuracy <- rbind(apply(FitAccuracy,2,"mean",na.rm=TRUE), 
                     apply(FitAccuracy,2,"sd",na.rm=TRUE),
                     apply(TestAccuracy,2,"mean",na.rm=TRUE),
                     apply(TestAccuracy,2,"sd",na.rm=TRUE))
colnames(RESaccuracy) = columna
rownames(RESaccuracy) = renglon
write.csv(RESaccuracy, file=paste0(archivo,"_accuracy",".csv"))
```

\newpage
## Precision Macro Average

```{r, echo=TRUE, eval=TRUE, fig.show="hold", include=TRUE, out.width="100%", warning=FALSE, message=FALSE} 
summary(FitPrecisionMacroAve) 
apply(FitPrecisionMacroAve,2,"sd",na.rm=TRUE)
summary(TestPrecisionMacroAve)
apply(TestPrecisionMacroAve,2,"sd",na.rm=TRUE)

RESprecision <- rbind(apply(FitPrecisionMacroAve,2,"mean",na.rm=TRUE), 
                      apply(FitPrecisionMacroAve,2,"sd",na.rm=TRUE),
                      apply(TestPrecisionMacroAve,2,"mean",na.rm=TRUE),
                      apply(TestPrecisionMacroAve,2,"sd",na.rm=TRUE))
colnames(RESprecision) = columna
rownames(RESprecision) = renglon
write.csv(RESprecision, file=paste0(archivo,"_precision",".csv"))
```

\newpage
## Recall Macro Average

```{r, echo=TRUE, eval=TRUE, fig.show="hold", include=TRUE, out.width="100%", warning=FALSE, message=FALSE} 
summary(FitRecallMacroAve) 
apply(FitRecallMacroAve,2,"sd",na.rm=TRUE)
summary(TestRecallMacroAve)
apply(TestRecallMacroAve,2,"sd",na.rm=TRUE)

RESrecall <- rbind(apply(FitRecallMacroAve,2,"mean",na.rm=TRUE), 
                   apply(FitRecallMacroAve,2,"sd",na.rm=TRUE),
                   apply(TestRecallMacroAve,2,"mean",na.rm=TRUE),
                   apply(TestRecallMacroAve,2,"sd",na.rm=TRUE))
colnames(RESrecall) = columna
rownames(RESrecall) = renglon
write.csv(RESrecall, file=paste0(archivo,"_recall",".csv"))
```

\newpage
## F1-Score Macro Average

```{r, echo=TRUE, eval=TRUE, fig.show="hold", include=TRUE, out.width="100%", warning=FALSE, message=FALSE} 
summary(FitF1ScoreMacroAve) 
apply(FitF1ScoreMacroAve,2,"sd",na.rm=TRUE)
summary(TestF1ScoreMacroAve)
apply(TestF1ScoreMacroAve,2,"sd",na.rm=TRUE)

RESf1score <- rbind(apply(FitF1ScoreMacroAve,2,"mean",na.rm=TRUE), 
                    apply(FitF1ScoreMacroAve,2,"sd",na.rm=TRUE),
                    apply(TestF1ScoreMacroAve,2,"mean",na.rm=TRUE),
                    apply(TestF1ScoreMacroAve,2,"sd",na.rm=TRUE))
colnames(RESf1score) = columna
rownames(RESf1score) = renglon
write.csv(RESf1score, file=paste0(archivo,"_f1score",".csv"))
``` 

